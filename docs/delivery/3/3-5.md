# [3-5] Integration Tests

[Back to task list](./tasks.md)

## Description

Create comprehensive integration tests for channel and playlist services and API endpoints. These tests verify the correct interaction between services, repositories, and the database layer, ensuring the complete channel management system works as expected with real database operations.

Integration tests complement unit tests by verifying the full stack of operations from API request through service layer to database and back.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-28 00:00:00 | Created | N/A | Proposed | Task file created | AI_Agent |

## Requirements

### Test Coverage Areas

1. **Channel Service Integration**
   - CRUD operations with real database
   - Validation enforcement
   - Error scenarios

2. **Playlist Service Integration**
   - Add/remove/reorder with transactions
   - Position management
   - Duration calculation

3. **Channel API Endpoints**
   - All HTTP endpoints
   - Request/response validation
   - Status codes

4. **Playlist API Endpoints**
   - All HTTP endpoints
   - Transaction handling
   - Error responses

### Technical Requirements
- Use test database (SQLite in-memory or file)
- Real GORM operations (no mocks for DB)
- HTTP testing with `httptest` package
- Test fixtures for media and channels
- Transaction verification
- Cleanup between tests
- Follow patterns from `media_test.go`

### Test Database Strategy
- Use separate test database file or in-memory SQLite
- Run migrations before tests
- Seed test data as needed
- Clean database between test suites
- Verify transaction rollback behavior

## Implementation Plan

### Step 1: Setup Test Infrastructure
Create `test/integration/channel_test.go`:
- Test database setup/teardown functions
- Helper functions for creating test channels
- Helper functions for creating test media
- Helper functions for HTTP request testing
- Common assertions

### Step 2: Channel Service Tests
Test the service layer with real database:
- Create channel success
- Create channel duplicate name (validation)
- Create channel invalid start time (validation)
- Get channel by ID
- Get channel not found
- List all channels
- Update channel success
- Update channel duplicate name
- Delete channel
- HasEmptyPlaylist check

### Step 3: Playlist Service Tests
Test playlist operations with transactions:
- Add media to playlist at position 0
- Add media with position conflict (verify shift)
- Add media with non-existent media ID
- Remove playlist item (verify reordering)
- Reorder playlist (verify transaction)
- Reorder transaction rollback on error
- Get playlist with media details
- Calculate total duration

### Step 4: Channel API Endpoint Tests
Test HTTP interface with `httptest`:
- POST /api/channels (success and errors)
- GET /api/channels (list)
- GET /api/channels/:id (success and not found)
- PUT /api/channels/:id (success, validation errors)
- DELETE /api/channels/:id (success and not found)
- GET /api/channels/:id/current (placeholder verification)

### Step 5: Playlist API Endpoint Tests
Test playlist HTTP endpoints:
- GET /api/channels/:id/playlist
- POST /api/channels/:id/playlist (success and errors)
- DELETE /api/channels/:id/playlist/:item_id
- PUT /api/channels/:id/playlist/reorder (atomic operation)

### Step 6: Cross-Cutting Concerns
- UUID validation in all endpoints
- Error response format consistency
- Logging output verification (if needed)
- Context timeout behavior

## Test Plan

### Objective
Verify the complete channel management system works correctly from API layer through to database with real operations.

### Test Scope
- Service layer with database integration
- API endpoints with HTTP testing
- Transaction handling
- Error scenarios
- Data integrity

### Key Test Scenarios

**Service Layer:**
1. Channel CRUD with real database operations
2. Name uniqueness validation prevents duplicates
3. Start time validation rejects far future dates
4. Playlist operations maintain position integrity
5. Transaction rollback on reorder failure
6. Duration calculation sums correctly

**API Layer:**
7. All endpoints return correct HTTP status codes
8. Request validation catches malformed input
9. UUID validation prevents invalid IDs
10. Error responses follow consistent format
11. Successful operations return expected data
12. Cascade deletion removes playlist items

**Integration:**
13. Create channel → add playlist → retrieve → verify
14. Add multiple items → reorder → verify positions
15. Remove item → verify subsequent items reordered
16. Delete channel → verify playlist items removed

### Success Criteria
- All integration tests pass
- Service layer works with real database
- API layer correctly calls services
- Transactions maintain data integrity
- Error handling produces correct responses
- Tests follow existing integration test patterns

## Verification

### Acceptance Criteria
- [ ] Test infrastructure set up (database, helpers)
- [ ] Channel service tests cover CRUD and validation
- [ ] Playlist service tests cover operations and transactions
- [ ] Channel API tests cover all endpoints
- [ ] Playlist API tests cover all endpoints
- [ ] Transaction behavior verified (commit/rollback)
- [ ] Error scenarios tested
- [ ] UUID validation tested
- [ ] Tests can run independently
- [ ] Tests clean up after themselves
- [ ] Test coverage >80% for services and API handlers

### Definition of Done
- All acceptance criteria met
- All integration tests pass
- Tests follow Go best practices
- No flaky tests
- Can run with `go test ./test/integration/...`
- Code coverage reports generated
- Tests documented with clear scenario names

## Files Modified

### New Files Created
- `api/test/integration/channel_test.go` - Main integration tests
- `api/test/integration/channel_fixtures.go` - Test fixtures and helpers (optional)

### Files Modified
- None (new test files only)

### API Specifications Updated
- None

## Notes

- Follow exact pattern from `test/integration/media_test.go`
- Use `t.Parallel()` for tests that can run concurrently
- Use `t.Cleanup()` for resource cleanup
- Test database should be isolated from development database
- Consider table-driven tests for similar scenarios
- Verify transaction behavior explicitly (start, commit, rollback)
- Use `httptest.NewRecorder()` for HTTP testing
- Mock only external dependencies (e.g., time for start time validation)
- Real database operations preferred over mocks for integration tests
- Include comments explaining complex test scenarios
- Group related tests using subtests (`t.Run()`)

