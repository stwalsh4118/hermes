# [4-5] Integration Tests

[Back to task list](./tasks.md)

## Description

Create integration tests that verify the complete timeline calculation flow from HTTP request through service layer to calculator and back. These tests use a real database (test instance) and real HTTP requests to validate the entire stack works correctly together.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-30 00:00:00 | Created | N/A | Proposed | Task file created | AI_Agent |

## Requirements

### Functional Requirements
- Test timeline calculation with real database
- Test HTTP endpoint with real requests
- Verify JSON response format
- Test all major scenarios (success and error cases)
- Use test fixtures for repeatable tests
- Clean up test data after each test

### Technical Requirements
- Create `api/test/integration/timeline_integration_test.go`
- Follow existing integration test patterns (see media_integration_test.go, channel_api_test.go)
- Use test helpers from `test/integration/helpers.go`
- Create test channels and playlists in database
- Make real HTTP requests to API
- Parse and validate responses

### Test Database
- Use SQLite in-memory database
- Run migrations
- Seed with test data
- Clean up between tests

## Implementation Plan

### Step 1: Create test file structure
- Create `api/test/integration/timeline_integration_test.go`
- Import required packages (testing, http, database, models)
- Set up test helpers

### Step 2: Create test fixtures
- Helper to create test channel
- Helper to create test media items
- Helper to add items to playlist
- Reusable test data builders

### Step 3: Test successful timeline calculation
- Create channel with known start time
- Add multiple media items to playlist
- Calculate expected current position
- Call API endpoint
- Verify response matches expectations

### Step 4: Test edge cases
- Empty playlist
- Channel not started yet
- Non-looping past end
- Loop boundary crossing

### Step 5: Test error handling
- Invalid channel ID (400)
- Non-existent channel (404)
- Various conflict scenarios (409)

### Step 6: Test multiple playlists
- Different channel configurations
- Different playlist lengths
- Looping vs non-looping

## Test Plan

### Objective
Verify complete timeline calculation flow works correctly with real database and HTTP requests.

### Test Scope
- Full stack integration (HTTP -> Service -> Calculator -> Database)
- Real database operations
- Real HTTP requests/responses
- JSON serialization

### Key Test Scenarios

1. **Successful Current Position - Mid Playlist**
   - Setup: Channel started 2 hours ago, 3 items (1h each)
   - Request: GET /api/channels/{id}/current
   - Expected: 200 OK, returns second item with correct offset

2. **Successful Current Position - Loop Boundary**
   - Setup: Looping channel, elapsed > total duration
   - Request: GET /api/channels/{id}/current
   - Expected: 200 OK, wraps to first item correctly

3. **Empty Playlist**
   - Setup: Channel with no playlist items
   - Request: GET /api/channels/{id}/current
   - Expected: 409 Conflict, clear error message

4. **Channel Not Started**
   - Setup: Channel start time in future
   - Request: GET /api/channels/{id}/current
   - Expected: 409 Conflict, "channel not started" message

5. **Playlist Finished**
   - Setup: Non-looping channel, all items completed
   - Request: GET /api/channels/{id}/current
   - Expected: 409 Conflict, "playlist finished" message

6. **Invalid Channel ID**
   - Setup: None
   - Request: GET /api/channels/invalid-uuid/current
   - Expected: 400 Bad Request

7. **Channel Not Found**
   - Setup: None
   - Request: GET /api/channels/{non-existent-uuid}/current
   - Expected: 404 Not Found

8. **Multiple Channels**
   - Setup: Multiple channels with different states
   - Request: Call endpoint for each channel
   - Expected: Each returns correct independent result

### Success Criteria
- All integration tests pass
- Tests are repeatable and deterministic
- Test data is properly cleaned up
- Tests run in reasonable time (< 5 seconds total)
- Test coverage for major scenarios

## Verification

### Acceptance Criteria
- [ ] Integration test file created
- [ ] Tests use real database (test instance)
- [ ] Tests make real HTTP requests
- [ ] Successful calculation test implemented
- [ ] Edge case tests implemented
- [ ] Error case tests implemented
- [ ] Response format validation
- [ ] HTTP status code validation
- [ ] All tests pass
- [ ] No test data leakage between tests

### Definition of Done
- All acceptance criteria met
- Integration tests pass consistently
- Code follows testing best practices
- Tests are maintainable and well-documented
- Ready for E2E CoS testing

## Files Modified

### New Files Created
- `api/test/integration/timeline_integration_test.go` - Integration tests

### Files Potentially Modified
- `api/test/integration/helpers.go` - Add timeline test helpers if needed

## Notes

- Follow patterns from existing integration tests
- Use table-driven tests for multiple scenarios
- Create realistic test data (proper media files not needed, just metadata)
- Test both looping and non-looping channels
- Verify timestamp fields are correctly formatted
- Ensure tests are timezone-safe (use UTC)
- Consider testing with various playlist sizes
- Integration tests complement unit tests, not replace them

